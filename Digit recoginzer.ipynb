{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Dropout,Dense,Flatten,BatchNormalization\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
    "x_train = x_train.reshape((x_train.shape[0], num_pixels)).astype('float32')\n",
    "x_test = x_test.reshape((x_test.shape[0], num_pixels)).astype('float32')\n",
    "x_train/=255\n",
    "x_test/=255\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\srstu\\Documents\\jupyter notebook\\Digit recognizer\\train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\srstu\\Documents\\jupyter notebook\\Digit recognizer\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
       "       'pixel7', 'pixel8', 'pixel9',\n",
       "       ...\n",
       "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
       "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
       "      dtype='object', length=784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = train['label']\n",
    "X_train = train.drop('label',axis=1)\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /=255\n",
    "test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ee756a0f08>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[10][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ee75753bc8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all output have almost equal number of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=np.concatenate((X_train, x_train,x_test), axis=0)\n",
    "# Y_train=np.concatenate((Y_train, y_train,y_test), axis=0)\n",
    "Y_train = to_categorical(Y_train,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,Y_train,Y_val = train_test_split(X_train,Y_train,test_size = 0.05, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39900, 28, 28, 1) (60000, 28, 28, 1)\n",
      "(39900, 10) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , x_train.shape)\n",
    "print(Y_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39900, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out .. .then complie it with an optimizer (rmsprop,sgd,adam etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv2D(filters=64, kernel_size = (5,5), padding='Same' ,activation = 'relu', input_shape=(28,28,1)))\n",
    "# model.add(Conv2D(filters=64, kernel_size = (5,5), padding= 'Same', activation = 'relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# # model.add(Dropout(0.25))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(filters=32, kernel_size = (5,5), padding='Same' ,activation = 'relu'))\n",
    "# model.add(Conv2D(filters=32, kernel_size = (3,3), padding= 'Same', activation = 'relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "# model.add(Dropout(0.20))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(256,activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Dense(256,activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# # model.add(Dropout(0.1))\n",
    "\n",
    "# # model.add(Dense(128,activation='relu'))\n",
    "# # # model.add(BatchNormalization())\n",
    "# # model.add(Dropout(0.25))\n",
    "\n",
    "# # model.add(Dense(128,activation='relu'))\n",
    "# # model.add(BatchNormalization())\n",
    "# # model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Dense(10,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenetmodel = Sequential()\n",
    "lenetmodel.add(Conv2D(filters=8, kernel_size = (5,5), padding='Same' ,activation = 'relu', input_shape=(28,28,1)))\n",
    "lenetmodel.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "lenetmodel.add(Conv2D(filters=16, kernel_size = (5,5), padding='Valid' ,activation = 'relu'))\n",
    "lenetmodel.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "lenetmodel.add(Flatten())\n",
    "\n",
    "lenetmodel.add(Dense(120,activation='relu'))\n",
    "lenetmodel.add(Dense(84,activation='relu'))\n",
    "lenetmodel.add(Dense(10,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = RMSprop(lr =0.001 ,rho=0.9, epsilon=1e-08,decay=0.0)\n",
    "optimizer = Adam(learning_rate=0.003, beta_1=0.9, beta_2=0.999, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizer , loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "lenetmodel.compile(optimizer=optimizer , loss='categorical_crossentropy' , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 10s - loss: 1.9824 - accuracy: 0.4335 - val_loss: 0.9307 - val_accuracy: 0.8376\n",
      "Epoch 2/20\n",
      " - 8s - loss: 3.3236 - accuracy: 0.4119 - val_loss: 4.8132 - val_accuracy: 0.1052\n",
      "Epoch 3/20\n",
      " - 7s - loss: 2.8032 - accuracy: 0.3697 - val_loss: 1.0638 - val_accuracy: 0.7776\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "Epoch 4/20\n",
      " - 7s - loss: 1.3940 - accuracy: 0.5760 - val_loss: 0.9418 - val_accuracy: 0.8014\n",
      "Epoch 5/20\n",
      " - 7s - loss: 1.5216 - accuracy: 0.4459 - val_loss: 0.8528 - val_accuracy: 0.7933\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "Epoch 6/20\n",
      " - 8s - loss: 1.2455 - accuracy: 0.6884 - val_loss: 0.8807 - val_accuracy: 0.8157\n",
      "Epoch 7/20\n",
      " - 7s - loss: 1.1297 - accuracy: 0.7082 - val_loss: 0.6744 - val_accuracy: 0.8810\n",
      "Epoch 8/20\n"
     ]
    }
   ],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)\n",
    "history = lenetmodel.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])\n",
    "# history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "#                               epochs = epochs, validation_data = (X_val,Y_val),\n",
    "#                               verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "#                               , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# history1 = model.fit(X_train,Y_train ,batch_size=batch_size ,epochs=epochs,\n",
    "#                     verbose=2 , validation_data=(X_val,Y_val), callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'] , color='b' , label ='Training loss')\n",
    "ax[0].plot(history.history['val_loss'] , color='r' , label='Validation loss')\n",
    "\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display some error results \n",
    "import math\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = math.ceil(errors_index.shape[0]/3)\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.ceil(5/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
